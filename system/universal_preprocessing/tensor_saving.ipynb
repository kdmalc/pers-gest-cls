{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cd907626",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "62b74a3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _B_normalize_block(block_np, demean=True, eps=1e-8):\n",
    "    \"\"\"\n",
    "    block_np: (T, D_block) numpy array for one biosignal (e.g., all IMU channels)\n",
    "    Returns: (T, D_block) normalized per $B (demean per channel, divide by shared std over block)\n",
    "    \"\"\"\n",
    "    if demean:\n",
    "        block_np = block_np - block_np.mean(axis=0, keepdims=True)  # per-channel demean\n",
    "    sigma = block_np.ravel().std(dtype=np.float64)\n",
    "    if sigma < eps:\n",
    "        return block_np  # flat signal; leave as-is\n",
    "    return block_np / sigma\n",
    "\n",
    "def preprocess_df_B_by_gesture(\n",
    "    data_df: pd.DataFrame,\n",
    "    biosignal_switch_ix: int = 72,   # [:switch) = IMU, [switch:] = EMG\n",
    "    trial_length: int = 64,\n",
    "    demean: bool = True,\n",
    "    eps: float = 1e-8,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Apply $B to every trial in the full dataframe.\n",
    "    Assumptions:\n",
    "      - data_df has ONLY sensor columns (no metadata), shape = (num_trials*trial_length, num_channels)\n",
    "      - IMU columns come first, EMG columns follow\n",
    "      - Each trial is a contiguous block of `trial_length` rows\n",
    "    Returns: DataFrame with same shape/columns as input.\n",
    "    \"\"\"\n",
    "    if data_df.isna().any().any():\n",
    "        print(\"Warning: NaNs detected in input; consider cleaning first.\")\n",
    "\n",
    "    num_rows, num_cols = data_df.shape\n",
    "    if num_rows % trial_length != 0:\n",
    "        raise ValueError(f\"Rows ({num_rows}) not divisible by trial_length ({trial_length}).\")\n",
    "\n",
    "    if not (0 < biosignal_switch_ix < num_cols):\n",
    "        raise ValueError(f\"biosignal_switch_ix {biosignal_switch_ix} must be in (0, {num_cols}).\")\n",
    "\n",
    "    num_trials = num_rows // trial_length\n",
    "    cols = data_df.columns\n",
    "    X = data_df.to_numpy(dtype=np.float64, copy=True)  # (N, D)\n",
    "\n",
    "    for t in range(num_trials):\n",
    "        s = t * trial_length\n",
    "        e = s + trial_length\n",
    "        trial = X[s:e, :]  # (T, D)\n",
    "\n",
    "        imu_block = trial[:, :biosignal_switch_ix]\n",
    "        emg_block = trial[:, biosignal_switch_ix:]\n",
    "\n",
    "        imu_block = _B_normalize_block(imu_block, demean=demean, eps=eps)\n",
    "        emg_block = _B_normalize_block(emg_block, demean=demean, eps=eps)\n",
    "\n",
    "        X[s:e, :biosignal_switch_ix] = imu_block\n",
    "        X[s:e, biosignal_switch_ix:] = emg_block\n",
    "\n",
    "    out = pd.DataFrame(X, columns=cols, index=data_df.index)\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6fcd46d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_full_yX_timeseries_df(config):\n",
    "    \"\"\"\n",
    "    Reads the raw pandas files, processes them, groups by PID and Gesture,\n",
    "    converts to pure PyTorch Tensors, and saves to disk.\n",
    "    This eliminates all Pandas memory leaks during DataLoader multiprocessing.\n",
    "    \"\"\"\n",
    "    print(\"Processing raw data into pure Tensor dictionaries...\")\n",
    "\n",
    "    emg_imu_pkl_full_path = config[\"emg_imu_pkl_full_path\"]\n",
    "    pwmd_xlsx_filepath = config[\"pwmd_xlsx_filepath\"]\n",
    "    pwoutmd_xlsx_filepath = config[\"pwoutmd_xlsx_filepath\"]\n",
    "    \n",
    "    data_df = pd.read_pickle(emg_imu_pkl_full_path)\n",
    "\n",
    "    metadata_cols = ['Participant', 'Gesture_ID', 'Gesture_Num']\n",
    "    metadata_cols_df = data_df[metadata_cols].rename(columns={\"Participant\": \"PID\"})\n",
    "    metadata_cols_df['Gesture_Num'] = metadata_cols_df['Gesture_Num'].astype(int)\n",
    "\n",
    "    # PID encoder\n",
    "    all_PIDs = metadata_cols_df['PID']\n",
    "    unique_PIDs = all_PIDs.unique()\n",
    "    PID_encoder = LabelEncoder().fit(unique_PIDs)\n",
    "\n",
    "    # Gesture encoder\n",
    "    gesture_ID_label_encoder = LabelEncoder()\n",
    "    metadata_cols_df['Enc_Gesture_ID'] = gesture_ID_label_encoder.fit_transform(metadata_cols_df['Gesture_ID'])\n",
    "    metadata_cols_df['Enc_PID'] = PID_encoder.transform(metadata_cols_df['PID'])\n",
    "\n",
    "    # Signals\n",
    "    X_df = data_df.drop(metadata_cols, axis=1)\n",
    "    ppd_B_X_df = preprocess_df_B_by_gesture(X_df)\n",
    "\n",
    "    # Demographics (with & without disabilities)\n",
    "    FULL_pwmd_demo_df = pd.read_excel(pwmd_xlsx_filepath)\n",
    "    \n",
    "    # Fix 1: Add .copy() to avoid SettingWithCopy warnings\n",
    "    pwmd_demo_df = FULL_pwmd_demo_df[[ \n",
    "        \"PID\", \"disability coding\", \"time disabled\", \"Actual handedness\", \n",
    "        \"What is your age?\", \"What is your gender?\", \"BMI\", \"DASH score\" \n",
    "    ]][:-8].copy()\n",
    "    # Fix 2: Use .str.strip() to access string methods on the Series\n",
    "    pwmd_demo_df[\"time disabled\"] = pd.to_numeric(\n",
    "        pwmd_demo_df[\"time disabled\"].astype(str).str.strip(), \n",
    "        errors='coerce'\n",
    "    )\n",
    "\n",
    "    numeric_cols = pwmd_demo_df.select_dtypes(include='number').columns\n",
    "    pwmd_demo_df[numeric_cols] = pwmd_demo_df[numeric_cols] / 100.0\n",
    "    pwmd_demo_df[\"BMI\"] = pwmd_demo_df[\"BMI\"] / 70.0\n",
    "    pwmd_demo_df['Enc_PID'] = PID_encoder.transform(pwmd_demo_df[\"PID\"])\n",
    "\n",
    "    FULL_pwoutmd_demo_df = pd.read_excel(pwoutmd_xlsx_filepath)\n",
    "    # 1. Added .copy() to ensure this is a standalone DataFrame\n",
    "    pwoutmd_demo_df = FULL_pwoutmd_demo_df[[\n",
    "        \"PID\", \"disability coding\", \"time disabled\", \"Actual handedness\",\n",
    "        \"What is your age?\", \"What is your gender?\", \"BMI\", \"DASH score\"\n",
    "    ]][:-5].copy()\n",
    "    # 2. Fixed the .str.strip() syntax\n",
    "    pwoutmd_demo_df[\"time disabled\"] = pd.to_numeric(\n",
    "        pwoutmd_demo_df[\"time disabled\"].astype(str).str.strip(), \n",
    "        errors='coerce'\n",
    "    )\n",
    "    # 3. Scale numeric columns\n",
    "    numeric_cols2 = pwoutmd_demo_df.select_dtypes(include='number').columns\n",
    "    pwoutmd_demo_df[numeric_cols2] = pwoutmd_demo_df[numeric_cols2] / 100.0\n",
    "    pwoutmd_demo_df[\"BMI\"] = pwoutmd_demo_df[\"BMI\"] / 70.0\n",
    "    pwoutmd_demo_df = pwoutmd_demo_df[~pwoutmd_demo_df['PID'].isin(['P001', 'P003'])]\n",
    "    pwoutmd_demo_df['Enc_PID'] = PID_encoder.transform(pwoutmd_demo_df[\"PID\"])\n",
    "\n",
    "    combined_demo_df = pd.concat([pwmd_demo_df, pwoutmd_demo_df])\n",
    "\n",
    "    demoENC_df = pd.get_dummies(\n",
    "        combined_demo_df,\n",
    "        columns=[\"disability coding\", \"Actual handedness\", \"What is your gender?\"],\n",
    "        drop_first=True\n",
    "    )\n",
    "    cols_to_convert = demoENC_df.columns.difference(['PID'])\n",
    "    demoENC_df[cols_to_convert] = demoENC_df[cols_to_convert].astype(float)\n",
    "\n",
    "    full_yX_timeseries_df = pd.concat([metadata_cols_df, ppd_B_X_df], axis=1)\n",
    "    return full_yX_timeseries_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a271869c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# DATA PREPARATION (Run Once & Save)\n",
    "# ==========================================\n",
    "def process_and_save_tensor_dict(config):\n",
    "    \"\"\"\n",
    "    Reads the raw pandas files, processes them, groups by PID and Gesture,\n",
    "    converts to pure PyTorch Tensors, and saves to disk.\n",
    "    This eliminates all Pandas memory leaks during DataLoader multiprocessing.\n",
    "    \"\"\"\n",
    "    print(\"Processing raw data into pure Tensor dictionaries...\")\n",
    "\n",
    "    emg_imu_pkl_full_path = config[\"emg_imu_pkl_full_path\"]\n",
    "    pwmd_xlsx_filepath = config[\"pwmd_xlsx_filepath\"]\n",
    "    pwoutmd_xlsx_filepath = config[\"pwoutmd_xlsx_filepath\"]\n",
    "    \n",
    "    # We want to build a dictionary structure: \n",
    "    # data_dict[PID][Gesture_Num] = { 'timeseries': Tensor(N, len), 'demo': Tensor(D) }\n",
    "    # [Insert your existing raw data loading logic here: pd.read_pickle, demographics, _B_normalize_block]\n",
    "    # For brevity, assuming you end up with `full_yX_timeseries_df` and `demoENC_df` as before.\n",
    "    # Imagine full_yX_timeseries_df has columns: ['PID', 'Gesture_Num', 'sensor_features...']\n",
    "    # And demoENC_df has demographics indexed by PID.\n",
    "    data_df = pd.read_pickle(emg_imu_pkl_full_path)\n",
    "\n",
    "    metadata_cols = ['Participant', 'Gesture_ID', 'Gesture_Num']\n",
    "    metadata_cols_df = data_df[metadata_cols].rename(columns={\"Participant\": \"PID\"})\n",
    "    metadata_cols_df['Gesture_Num'] = metadata_cols_df['Gesture_Num'].astype(int)\n",
    "\n",
    "    # PID encoder\n",
    "    all_PIDs = metadata_cols_df['PID']\n",
    "    unique_PIDs = all_PIDs.unique()\n",
    "    PID_encoder = LabelEncoder().fit(unique_PIDs)\n",
    "\n",
    "    # Gesture encoder\n",
    "    gesture_ID_label_encoder = LabelEncoder()\n",
    "    metadata_cols_df['Enc_Gesture_ID'] = gesture_ID_label_encoder.fit_transform(metadata_cols_df['Gesture_ID'])\n",
    "    metadata_cols_df['Enc_PID'] = PID_encoder.transform(metadata_cols_df['PID'])\n",
    "\n",
    "    # Signals\n",
    "    X_df = data_df.drop(metadata_cols, axis=1)\n",
    "    ppd_B_X_df = preprocess_df_B_by_gesture(X_df)\n",
    "\n",
    "    # Demographics (with & without disabilities)\n",
    "    FULL_pwmd_demo_df = pd.read_excel(pwmd_xlsx_filepath)\n",
    "    \n",
    "    # Fix 1: Add .copy() to avoid SettingWithCopy warnings\n",
    "    pwmd_demo_df = FULL_pwmd_demo_df[[ \n",
    "        \"PID\", \"disability coding\", \"time disabled\", \"Actual handedness\", \n",
    "        \"What is your age?\", \"What is your gender?\", \"BMI\", \"DASH score\" \n",
    "    ]][:-8].copy()\n",
    "    # Fix 2: Use .str.strip() to access string methods on the Series\n",
    "    pwmd_demo_df[\"time disabled\"] = pd.to_numeric(\n",
    "        pwmd_demo_df[\"time disabled\"].astype(str).str.strip(), \n",
    "        errors='coerce'\n",
    "    )\n",
    "\n",
    "    numeric_cols = pwmd_demo_df.select_dtypes(include='number').columns\n",
    "    pwmd_demo_df[numeric_cols] = pwmd_demo_df[numeric_cols] / 100.0\n",
    "    pwmd_demo_df[\"BMI\"] = pwmd_demo_df[\"BMI\"] / 70.0\n",
    "    pwmd_demo_df['Enc_PID'] = PID_encoder.transform(pwmd_demo_df[\"PID\"])\n",
    "\n",
    "    ##########################################################################\n",
    "    # --- Verification Prints ---\n",
    "    print(\"--- Data Integrity Check ---\")\n",
    "    print(f\"Total rows after slice: {len(pwmd_demo_df)}\")\n",
    "    # Check how many values failed to convert to numeric (resulted in NaN)\n",
    "    nans_created = pwmd_demo_df[\"time disabled\"].isna().sum()\n",
    "    print(f\"Rows that couldn't be converted (set to NaN): {nans_created}\")\n",
    "    # Show a sample of the 'time disabled' column to verify values\n",
    "    print(\"\\nSample of 'time disabled' after conversion:\")\n",
    "    print(pwmd_demo_df[\"time disabled\"].head())\n",
    "    # Verify the division worked on numeric columns\n",
    "    print(\"\\nMax value in numeric columns (should be small if divided by 100):\")\n",
    "    print(pwmd_demo_df[numeric_cols].max())\n",
    "    ##########################################################################\n",
    "\n",
    "    ##########################################################\n",
    "    print(\"\\n--- pwmd_demo_df: First Row Entry ---\")\n",
    "    print(f\"Unique disability codings: {pwmd_demo_df['disability coding'].unique()}\")\n",
    "    print(pwmd_demo_df.head(1))\n",
    "    ##########################################################\n",
    "\n",
    "    FULL_pwoutmd_demo_df = pd.read_excel(pwoutmd_xlsx_filepath)\n",
    "    # 1. Added .copy() to ensure this is a standalone DataFrame\n",
    "    pwoutmd_demo_df = FULL_pwoutmd_demo_df[[\n",
    "        \"PID\", \"disability coding\", \"time disabled\", \"Actual handedness\",\n",
    "        \"What is your age?\", \"What is your gender?\", \"BMI\", \"DASH score\"\n",
    "    ]][:-5].copy()\n",
    "    # 2. Fixed the .str.strip() syntax\n",
    "    pwoutmd_demo_df[\"time disabled\"] = pd.to_numeric(\n",
    "        pwoutmd_demo_df[\"time disabled\"].astype(str).str.strip(), \n",
    "        errors='coerce'\n",
    "    )\n",
    "    # 3. Scale numeric columns\n",
    "    numeric_cols2 = pwoutmd_demo_df.select_dtypes(include='number').columns\n",
    "    pwoutmd_demo_df[numeric_cols2] = pwoutmd_demo_df[numeric_cols2] / 100.0\n",
    "    pwoutmd_demo_df[\"BMI\"] = pwoutmd_demo_df[\"BMI\"] / 70.0\n",
    "    pwoutmd_demo_df = pwoutmd_demo_df[~pwoutmd_demo_df['PID'].isin(['P001', 'P003'])]\n",
    "    pwoutmd_demo_df['Enc_PID'] = PID_encoder.transform(pwoutmd_demo_df[\"PID\"])\n",
    "\n",
    "    ##########################################################\n",
    "    print(\"\\n--- pwoutmd_demo_df: First Row Entry ---\")\n",
    "    print(f\"Unique disability codings: {pwoutmd_demo_df['disability coding'].unique()}\")\n",
    "    print(pwoutmd_demo_df.head(1))\n",
    "    ##########################################################\n",
    "\n",
    "    combined_demo_df = pd.concat([pwmd_demo_df, pwoutmd_demo_df])\n",
    "\n",
    "    # 1. Generate dummies but KEEP the 'PID' column for now\n",
    "    # 1. Create dummies (which produces the True/False columns)\n",
    "    demoENC_df = pd.get_dummies(\n",
    "        combined_demo_df,\n",
    "        columns=[\"disability coding\", \"Actual handedness\", \"What is your gender?\"],\n",
    "        drop_first=True\n",
    "    )\n",
    "\n",
    "    # 2. Convert the entire DataFrame (except PID) to float immediately\n",
    "    # This turns True -> 1.0 and False -> 0.0\n",
    "    cols_to_convert = demoENC_df.columns.difference(['PID'])\n",
    "    demoENC_df[cols_to_convert] = demoENC_df[cols_to_convert].astype(float)\n",
    "\n",
    "    # REMOVE THIS LINE: \n",
    "    # TODO: Why did I remove this? I dont think PID or Enc_PID get used in the demographic embedding vector (gotta find where that is...)\n",
    "    # demoENC_df.drop(columns=[\"PID\"], inplace=True) \n",
    "\n",
    "    ###############################################################################\n",
    "    ###   DEBUGGING DEMOGRAPHICS   ###\n",
    "    # TODO: Do I want it to include (Enc_)PID or not?\n",
    "    ## For ML, no\n",
    "    ## But presumably this is the only place where PID is passed through? Which would be useful for MOE and conditioning...\n",
    "    ## Is this the only place where it is passsed through?\n",
    "    # 1. Print the shape (Rows, Columns)\n",
    "    print(f\"Shape of DataFrame: {demoENC_df.shape}\")\n",
    "    # 2. Print the column names as a list (so you can count them easily)\n",
    "    print(f\"\\n--- Names of the {len(demoENC_df.columns.tolist())} Columns ---\")\n",
    "    print(demoENC_df.columns.tolist())\n",
    "    # 3. Print the first row to see the data types and values\n",
    "    print(\"\\n--- First Row Entry ---\")\n",
    "    print(demoENC_df.head(1))\n",
    "    ###############################################################################\n",
    "\n",
    "    full_yX_timeseries_df = pd.concat([metadata_cols_df, ppd_B_X_df], axis=1)\n",
    "\n",
    "    data_dict = {}\n",
    "    pids = full_yX_timeseries_df['PID'].unique()\n",
    "\n",
    "    for pid in pids:\n",
    "        data_dict[pid] = {}\n",
    "        pid_data = full_yX_timeseries_df[full_yX_timeseries_df['PID'] == pid]\n",
    "\n",
    "        all_cols = pid_data.columns.tolist()\n",
    "        emg_cols = [c for c in all_cols if 'EMG' in str(c).upper()]\n",
    "        imu_cols = [c for c in all_cols if 'IMU' in str(c).upper()]\n",
    "\n",
    "        # LOGGING: Always print this once so you can verify the count!\n",
    "        print(f\"Detected {len(emg_cols)} EMG columns and {len(imu_cols)} IMU columns.\")\n",
    "        \n",
    "        # 2. Filter using 'PID', then drop BOTH 'PID' and 'Enc_PID' \n",
    "        # before converting the remaining numeric values to a tensor.\n",
    "        matching_demo = demoENC_df[demoENC_df['PID'] == pid]\n",
    "        \n",
    "        if not matching_demo.empty:\n",
    "            # Drop the ID columns so they aren't part of the feature vector\n",
    "            features = matching_demo.drop(columns=['PID', 'Enc_PID']).values[0]\n",
    "            demo_tensor = torch.tensor(features, dtype=torch.float32)\n",
    "        else:\n",
    "            print(f\"Skipping {pid}: No demographic match found.\")\n",
    "            continue\n",
    "        \n",
    "        gestures = pid_data['Gesture_Num'].unique()\n",
    "        for g in gestures:\n",
    "            # Filter for specific gesture (this currently grabs all 640 rows)\n",
    "            g_df = pid_data[pid_data['Gesture_Num'] == g]\n",
    "            \n",
    "            # 1. Extract the raw numpy values\n",
    "            emg_raw = g_df[emg_cols].values # Shape: (640, 16)\n",
    "            imu_raw = g_df[imu_cols].values # Shape: (640, 72)\n",
    "            \n",
    "            # 2. Convert to Tensors and RESHAPE to (Trials, Time, Channels)\n",
    "            # We use .view(10, 64, -1) which means: \n",
    "            # 10 trials, 64 time points, and \"calculate the rest\" for channels.\n",
    "            try:\n",
    "                emg_tensor = torch.tensor(emg_raw, dtype=torch.float32).view(10, 64, 16)\n",
    "                imu_tensor = torch.tensor(imu_raw, dtype=torch.float32).view(10, 64, 72)\n",
    "            except RuntimeError as e:\n",
    "                print(f\"Error reshaping PID {pid} Gesture {g}: {e}\")\n",
    "                print(f\"Actual shape was {emg_raw.shape}. Expected 640 rows.\")\n",
    "                continue\n",
    "\n",
    "            data_dict[pid][g] = {\n",
    "                'emg': emg_tensor, # Now shape (10, 64, 16)\n",
    "                'imu': imu_tensor, # Now shape (10, 64, 72)\n",
    "                'demo': demo_tensor\n",
    "            }\n",
    "            \n",
    "    save_path = os.path.join(config[\"dfs_save_path\"], f\"{config['timestamp']}_tensor_dict.pkl\")\n",
    "    with open(save_path, 'wb') as f:\n",
    "        pickle.dump(data_dict, f)\n",
    "    print(f\"Saved clean Tensor dictionary to {save_path}\")\n",
    "    return save_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "80466eb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0bc49069",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {}\n",
    "\n",
    "config[\"timestamp\"] = timestamp\n",
    "config[\"emg_imu_pkl_full_path\"] = 'C:\\\\Users\\\\kdmen\\\\Box\\\\Yamagami Lab\\\\Data\\\\Meta_Gesture_Project\\\\filtered_datasets\\\\metadata_IMU_EMG_allgestures_allusers.pkl'\n",
    "config[\"pwmd_xlsx_filepath\"] = \"C:\\\\Users\\\\kdmen\\\\Repos\\\\pers-gest-cls\\\\dataset\\\\Biosignal gesture questionnaire for participants with disabilities.xlsx\"\n",
    "config[\"pwoutmd_xlsx_filepath\"] = \"C:\\\\Users\\\\kdmen\\\\Repos\\\\pers-gest-cls\\\\dataset\\\\Biosignal gesture questionnaire for participants without disabilities.xlsx\"\n",
    "config[\"dfs_save_path\"] = \"C:\\\\Users\\\\kdmen\\\\Repos\\\\pers-gest-cls\\\\dataset\\\\meta-learning-sup-que-ds\\\\\"\n",
    "config[\"dfs_load_path\"] = \"C:\\\\Users\\\\kdmen\\\\Repos\\\\pers-gest-cls\\\\dataset\\\\meta-learning-sup-que-ds\\\\\"\n",
    "config[\"saved_df_timestamp\"] = '20250917_1217'\n",
    "config[\"user_split_json_filepath\"] = \"C:\\\\Users\\\\kdmen\\\\Repos\\\\pers-gest-cls\\\\system\\\\fixed_user_splits\\\\4kfcv_splits_shared_test.json\"\n",
    "config[\"results_save_dir\"] = f\"C:\\\\Users\\\\kdmen\\\\Repos\\\\pers-gest-cls\\\\system\\\\results\\\\local_{timestamp}\"\n",
    "config[\"models_save_dir\"] = f\"C:\\\\Users\\\\kdmen\\\\Repos\\\\pers-gest-cls\\\\system\\\\models\\\\local_{timestamp}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "374a6e7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing raw data into pure Tensor dictionaries...\n",
      "--- Data Integrity Check ---\n",
      "Total rows after slice: 26\n",
      "Rows that couldn't be converted (set to NaN): 0\n",
      "\n",
      "Sample of 'time disabled' after conversion:\n",
      "0    0.35\n",
      "1    0.20\n",
      "2    0.10\n",
      "3    0.52\n",
      "4    0.31\n",
      "Name: time disabled, dtype: float64\n",
      "\n",
      "Max value in numeric columns (should be small if divided by 100):\n",
      "time disabled        0.52\n",
      "What is your age?    0.77\n",
      "DASH score           0.82\n",
      "dtype: float64\n",
      "\n",
      "--- pwmd_demo_df: First Row Entry ---\n",
      "Unique disability codings: ['SCI' 'other' 'MD' 'PN' 'ET']\n",
      "    PID disability coding  time disabled Actual handedness  What is your age?   \n",
      "0  P102               SCI           0.35             Right               0.61  \\\n",
      "\n",
      "  What is your gender?      BMI  DASH score  Enc_PID  \n",
      "0                Woman  0.42188        0.39        6  \n",
      "\n",
      "--- pwoutmd_demo_df: First Row Entry ---\n",
      "Unique disability codings: ['No Disability']\n",
      "    PID disability coding  time disabled Actual handedness  What is your age?   \n",
      "2  P004     No Disability            0.0             Right               0.27  \\\n",
      "\n",
      "  What is your gender?       BMI  DASH score  Enc_PID  \n",
      "2                Woman  0.003043         0.0        0  \n",
      "Shape of DataFrame: (32, 14)\n",
      "\n",
      "--- Names of the 14 Columns ---\n",
      "['PID', 'time disabled', 'What is your age?', 'BMI', 'DASH score', 'Enc_PID', 'disability coding_MD', 'disability coding_No Disability', 'disability coding_PN', 'disability coding_SCI', 'disability coding_other', 'Actual handedness_Right', 'What is your gender?_Non-binary', 'What is your gender?_Woman']\n",
      "\n",
      "--- First Row Entry ---\n",
      "    PID  time disabled  What is your age?      BMI  DASH score  Enc_PID   \n",
      "0  P102           0.35               0.61  0.42188        0.39      6.0  \\\n",
      "\n",
      "   disability coding_MD  disability coding_No Disability   \n",
      "0                   0.0                              0.0  \\\n",
      "\n",
      "   disability coding_PN  disability coding_SCI  disability coding_other   \n",
      "0                   0.0                    1.0                      0.0  \\\n",
      "\n",
      "   Actual handedness_Right  What is your gender?_Non-binary   \n",
      "0                      1.0                              0.0  \\\n",
      "\n",
      "   What is your gender?_Woman  \n",
      "0                         1.0  \n",
      "Detected 16 EMG columns and 72 IMU columns.\n",
      "Detected 16 EMG columns and 72 IMU columns.\n",
      "Detected 16 EMG columns and 72 IMU columns.\n",
      "Detected 16 EMG columns and 72 IMU columns.\n",
      "Detected 16 EMG columns and 72 IMU columns.\n",
      "Detected 16 EMG columns and 72 IMU columns.\n",
      "Detected 16 EMG columns and 72 IMU columns.\n",
      "Detected 16 EMG columns and 72 IMU columns.\n",
      "Detected 16 EMG columns and 72 IMU columns.\n",
      "Detected 16 EMG columns and 72 IMU columns.\n",
      "Detected 16 EMG columns and 72 IMU columns.\n",
      "Detected 16 EMG columns and 72 IMU columns.\n",
      "Detected 16 EMG columns and 72 IMU columns.\n",
      "Detected 16 EMG columns and 72 IMU columns.\n",
      "Detected 16 EMG columns and 72 IMU columns.\n",
      "Detected 16 EMG columns and 72 IMU columns.\n",
      "Detected 16 EMG columns and 72 IMU columns.\n",
      "Detected 16 EMG columns and 72 IMU columns.\n",
      "Detected 16 EMG columns and 72 IMU columns.\n",
      "Detected 16 EMG columns and 72 IMU columns.\n",
      "Detected 16 EMG columns and 72 IMU columns.\n",
      "Detected 16 EMG columns and 72 IMU columns.\n",
      "Detected 16 EMG columns and 72 IMU columns.\n",
      "Detected 16 EMG columns and 72 IMU columns.\n",
      "Detected 16 EMG columns and 72 IMU columns.\n",
      "Detected 16 EMG columns and 72 IMU columns.\n",
      "Detected 16 EMG columns and 72 IMU columns.\n",
      "Detected 16 EMG columns and 72 IMU columns.\n",
      "Detected 16 EMG columns and 72 IMU columns.\n",
      "Detected 16 EMG columns and 72 IMU columns.\n",
      "Detected 16 EMG columns and 72 IMU columns.\n",
      "Detected 16 EMG columns and 72 IMU columns.\n",
      "Saved clean Tensor dictionary to C:\\Users\\kdmen\\Repos\\pers-gest-cls\\dataset\\meta-learning-sup-que-ds\\20260220_1338_tensor_dict.pkl\n"
     ]
    }
   ],
   "source": [
    "save_location = process_and_save_tensor_dict(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "427c6ffc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "82fc1078",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Users: 32\n",
      "\n",
      "--- Inspecting User: P102, Gesture: 1 ---\n",
      "EMG Shape:  torch.Size([10, 64, 16])  (Expected: [Timesteps, 16])\n",
      "IMU Shape:  torch.Size([10, 64, 72])  (Expected: [Timesteps, 72])\n",
      "Demo Shape: torch.Size([11])\n",
      "\n",
      "Data looks clean (no NaNs).\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import torch\n",
    "\n",
    "# Path to the tensor_dict.pkl you just created\n",
    "file_path = \"C:\\\\Users\\\\kdmen\\\\Repos\\\\pers-gest-cls\\\\dataset\\\\meta-learning-sup-que-ds\\\\maml_tensor_dict.pkl\"\n",
    "\n",
    "with open(file_path, 'rb') as f:\n",
    "    data_dict = pickle.load(f)\n",
    "\n",
    "# 1. See how many PIDs (users) are in there\n",
    "pids = list(data_dict.keys())\n",
    "print(f\"Total Users: {len(pids)}\")\n",
    "\n",
    "# 2. Pick the first user and the first gesture to inspect shapes\n",
    "sample_pid = pids[0]\n",
    "sample_gesture = list(data_dict[sample_pid].keys())[0]\n",
    "sample_data = data_dict[sample_pid][sample_gesture]\n",
    "\n",
    "print(f\"\\n--- Inspecting User: {sample_pid}, Gesture: {sample_gesture} ---\")\n",
    "print(f\"EMG Shape:  {sample_data['emg'].shape}  (Expected: [Timesteps, 16])\")\n",
    "print(f\"IMU Shape:  {sample_data['imu'].shape}  (Expected: [Timesteps, 72])\")\n",
    "print(f\"Demo Shape: {sample_data['demo'].shape}\")\n",
    "\n",
    "# 3. Check for NaNs (important for training stability)\n",
    "if torch.isnan(sample_data['emg']).any():\n",
    "    print(\"\\nWARNING: Found NaNs in EMG data!\")\n",
    "else:\n",
    "    print(\"\\nData looks clean (no NaNs).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce7e1c45",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "41c3c4da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "def verify_segmentation(original_df, tensor_dict_path, pid='P102', gesture_num=1):\n",
    "    # 1. Load the saved Tensor Dictionary\n",
    "    with open(tensor_dict_path, 'rb') as f:\n",
    "        data_dict = pickle.load(f)\n",
    "    \n",
    "    # 2. Extract Trial 0 (the first 64 rows) from the Tensor\n",
    "    # Shape: (10, 64, 16) -> We take [0, :10, 0] to see the first 10 timepoints of the 1st channel\n",
    "    tensor_emg = data_dict[pid][gesture_num]['emg']\n",
    "    trial_0_first_10_tensor = tensor_emg[0, :10, 0].numpy() \n",
    "\n",
    "    # 3. Extract the same values from the original Pandas DF\n",
    "    # We filter by PID and Gesture, then take the first 10 rows of the first EMG column\n",
    "    emg_cols = [c for c in original_df.columns if 'EMG' in str(c).upper()]\n",
    "    first_emg_col = emg_cols[0]\n",
    "    \n",
    "    df_segment = original_df[(original_df['PID'] == pid) & \n",
    "                             (original_df['Gesture_Num'] == gesture_num)]\n",
    "    \n",
    "    # In the original DF, the first 10 rows of this gesture SHOULD be Trial 0\n",
    "    df_first_10_values = df_segment[first_emg_col].iloc[:10].values\n",
    "\n",
    "    # 4. Compare\n",
    "    print(f\"--- Verification for User {pid}, Gesture {gesture_num} ---\")\n",
    "    print(f\"EMG Column tested: {first_emg_col}\")\n",
    "    print(f\"{'Index':<8} | {'Original DF Value':<20} | {'Tensor (Trial 0) Value':<20}\")\n",
    "    print(\"-\" * 60)\n",
    "    \n",
    "    matches = 0\n",
    "    for i in range(10):\n",
    "        val_df = df_first_10_values[i]\n",
    "        val_tensor = trial_0_first_10_tensor[i]\n",
    "        is_match = np.isclose(val_df, val_tensor, atol=1e-5)\n",
    "        match_str = \"MATCH\" if is_match else \"MISMATCH!\"\n",
    "        if is_match: matches += 1\n",
    "        \n",
    "        print(f\"{i:<8} | {val_df:<20.6f} | {val_tensor:<20.6f} | {match_str}\")\n",
    "\n",
    "    if matches == 10:\n",
    "        print(\"\\n✅ SUCCESS: The first 10 rows of the DataFrame mapped perfectly to Trial 0, Time 0-9.\")\n",
    "    else:\n",
    "        print(\"\\n❌ ERROR: Values do not match. The slicing or reshaping logic is offset.\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a7e67e16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing raw data into pure Tensor dictionaries...\n",
      "(204800, 93)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PID</th>\n",
       "      <th>Gesture_ID</th>\n",
       "      <th>Gesture_Num</th>\n",
       "      <th>Enc_Gesture_ID</th>\n",
       "      <th>Enc_PID</th>\n",
       "      <th>IMU1_ax</th>\n",
       "      <th>IMU1_ay</th>\n",
       "      <th>IMU1_az</th>\n",
       "      <th>IMU1_vx</th>\n",
       "      <th>IMU1_vy</th>\n",
       "      <th>...</th>\n",
       "      <th>EMG7</th>\n",
       "      <th>EMG8</th>\n",
       "      <th>EMG9</th>\n",
       "      <th>EMG10</th>\n",
       "      <th>EMG11</th>\n",
       "      <th>EMG12</th>\n",
       "      <th>EMG13</th>\n",
       "      <th>EMG14</th>\n",
       "      <th>EMG15</th>\n",
       "      <th>EMG16</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>P102</td>\n",
       "      <td>pan</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>-0.551109</td>\n",
       "      <td>-0.738972</td>\n",
       "      <td>-0.985439</td>\n",
       "      <td>0.181924</td>\n",
       "      <td>0.059616</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.276292</td>\n",
       "      <td>-0.026736</td>\n",
       "      <td>-0.873870</td>\n",
       "      <td>-1.036152</td>\n",
       "      <td>-0.580930</td>\n",
       "      <td>-0.719494</td>\n",
       "      <td>-0.502255</td>\n",
       "      <td>-1.750091</td>\n",
       "      <td>-0.127847</td>\n",
       "      <td>-0.094192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>P102</td>\n",
       "      <td>pan</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>-0.571115</td>\n",
       "      <td>-0.821726</td>\n",
       "      <td>-0.975036</td>\n",
       "      <td>0.242607</td>\n",
       "      <td>0.067375</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.125822</td>\n",
       "      <td>0.089679</td>\n",
       "      <td>-0.816215</td>\n",
       "      <td>-2.082635</td>\n",
       "      <td>-0.006283</td>\n",
       "      <td>-0.139439</td>\n",
       "      <td>-0.367764</td>\n",
       "      <td>-0.208084</td>\n",
       "      <td>-0.111811</td>\n",
       "      <td>-0.039009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>P102</td>\n",
       "      <td>pan</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>-0.509305</td>\n",
       "      <td>-0.823575</td>\n",
       "      <td>-0.947221</td>\n",
       "      <td>0.550111</td>\n",
       "      <td>0.013848</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.068451</td>\n",
       "      <td>0.117076</td>\n",
       "      <td>-0.668221</td>\n",
       "      <td>-3.403064</td>\n",
       "      <td>-0.526030</td>\n",
       "      <td>-0.478294</td>\n",
       "      <td>-0.300443</td>\n",
       "      <td>0.203266</td>\n",
       "      <td>0.113300</td>\n",
       "      <td>0.004728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>P102</td>\n",
       "      <td>pan</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>-0.511788</td>\n",
       "      <td>-0.775810</td>\n",
       "      <td>-0.947939</td>\n",
       "      <td>0.417919</td>\n",
       "      <td>0.087222</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.058907</td>\n",
       "      <td>0.080977</td>\n",
       "      <td>-0.424416</td>\n",
       "      <td>-3.709413</td>\n",
       "      <td>-0.570894</td>\n",
       "      <td>-0.775155</td>\n",
       "      <td>-0.144710</td>\n",
       "      <td>-0.619539</td>\n",
       "      <td>0.146499</td>\n",
       "      <td>0.199975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>P102</td>\n",
       "      <td>pan</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>-0.441369</td>\n",
       "      <td>-0.921726</td>\n",
       "      <td>-0.882652</td>\n",
       "      <td>1.254970</td>\n",
       "      <td>0.108993</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.003929</td>\n",
       "      <td>0.041526</td>\n",
       "      <td>-0.016530</td>\n",
       "      <td>-4.075150</td>\n",
       "      <td>-0.127710</td>\n",
       "      <td>2.682791</td>\n",
       "      <td>-0.141750</td>\n",
       "      <td>-0.208404</td>\n",
       "      <td>-0.035642</td>\n",
       "      <td>0.172662</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 93 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    PID Gesture_ID  Gesture_Num  Enc_Gesture_ID  Enc_PID   IMU1_ax   IMU1_ay   \n",
       "0  P102        pan            1               5        6 -0.551109 -0.738972  \\\n",
       "1  P102        pan            1               5        6 -0.571115 -0.821726   \n",
       "2  P102        pan            1               5        6 -0.509305 -0.823575   \n",
       "3  P102        pan            1               5        6 -0.511788 -0.775810   \n",
       "4  P102        pan            1               5        6 -0.441369 -0.921726   \n",
       "\n",
       "    IMU1_az   IMU1_vx   IMU1_vy  ...      EMG7      EMG8      EMG9     EMG10   \n",
       "0 -0.985439  0.181924  0.059616  ... -0.276292 -0.026736 -0.873870 -1.036152  \\\n",
       "1 -0.975036  0.242607  0.067375  ... -0.125822  0.089679 -0.816215 -2.082635   \n",
       "2 -0.947221  0.550111  0.013848  ... -0.068451  0.117076 -0.668221 -3.403064   \n",
       "3 -0.947939  0.417919  0.087222  ... -0.058907  0.080977 -0.424416 -3.709413   \n",
       "4 -0.882652  1.254970  0.108993  ... -0.003929  0.041526 -0.016530 -4.075150   \n",
       "\n",
       "      EMG11     EMG12     EMG13     EMG14     EMG15     EMG16  \n",
       "0 -0.580930 -0.719494 -0.502255 -1.750091 -0.127847 -0.094192  \n",
       "1 -0.006283 -0.139439 -0.367764 -0.208084 -0.111811 -0.039009  \n",
       "2 -0.526030 -0.478294 -0.300443  0.203266  0.113300  0.004728  \n",
       "3 -0.570894 -0.775155 -0.144710 -0.619539  0.146499  0.199975  \n",
       "4 -0.127710  2.682791 -0.141750 -0.208404 -0.035642  0.172662  \n",
       "\n",
       "[5 rows x 93 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_yX_timeseries_df = return_full_yX_timeseries_df(config)\n",
    "save_path = save_location\n",
    "\n",
    "print(full_yX_timeseries_df.shape)\n",
    "full_yX_timeseries_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "738c1bdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Verification for User P102, Gesture 1 ---\n",
      "EMG Column tested: EMG1\n",
      "Index    | Original DF Value    | Tensor (Trial 0) Value\n",
      "------------------------------------------------------------\n",
      "0        | -0.362743            | -0.362743            | MATCH\n",
      "1        | -0.351553            | -0.351553            | MATCH\n",
      "2        | -0.380825            | -0.380825            | MATCH\n",
      "3        | -0.366795            | -0.366795            | MATCH\n",
      "4        | -0.245578            | -0.245578            | MATCH\n",
      "5        | -0.171063            | -0.171063            | MATCH\n",
      "6        | -0.201667            | -0.201667            | MATCH\n",
      "7        | -0.165951            | -0.165951            | MATCH\n",
      "8        | -0.014897            | -0.014897            | MATCH\n",
      "9        | 0.034381             | 0.034381             | MATCH\n",
      "\n",
      "✅ SUCCESS: The first 10 rows of the DataFrame mapped perfectly to Trial 0, Time 0-9.\n"
     ]
    }
   ],
   "source": [
    "verify_segmentation(full_yX_timeseries_df, save_path, pid='P102', gesture_num=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "970afec8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Verification for User P112, Gesture 3 ---\n",
      "EMG Column tested: EMG1\n",
      "Index    | Original DF Value    | Tensor (Trial 0) Value\n",
      "------------------------------------------------------------\n",
      "0        | -0.043198            | -0.043198            | MATCH\n",
      "1        | -0.030466            | -0.030466            | MATCH\n",
      "2        | -0.049066            | -0.049066            | MATCH\n",
      "3        | -0.070309            | -0.070309            | MATCH\n",
      "4        | -0.069989            | -0.069989            | MATCH\n",
      "5        | -0.036132            | -0.036132            | MATCH\n",
      "6        | -0.037199            | -0.037199            | MATCH\n",
      "7        | -0.048633            | -0.048633            | MATCH\n",
      "8        | -0.054633            | -0.054633            | MATCH\n",
      "9        | -0.034075            | -0.034075            | MATCH\n",
      "\n",
      "✅ SUCCESS: The first 10 rows of the DataFrame mapped perfectly to Trial 0, Time 0-9.\n"
     ]
    }
   ],
   "source": [
    "verify_segmentation(full_yX_timeseries_df, save_path, pid='P112', gesture_num=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ee80e184",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Verification for User P124, Gesture 7 ---\n",
      "EMG Column tested: EMG1\n",
      "Index    | Original DF Value    | Tensor (Trial 0) Value\n",
      "------------------------------------------------------------\n",
      "0        | -0.221235            | -0.221235            | MATCH\n",
      "1        | -0.215883            | -0.215883            | MATCH\n",
      "2        | -0.209682            | -0.209682            | MATCH\n",
      "3        | -0.150030            | -0.150030            | MATCH\n",
      "4        | 0.104091             | 0.104091             | MATCH\n",
      "5        | 0.501215             | 0.501215             | MATCH\n",
      "6        | 0.570865             | 0.570865             | MATCH\n",
      "7        | 0.292914             | 0.292914             | MATCH\n",
      "8        | 0.324206             | 0.324206             | MATCH\n",
      "9        | 0.342103             | 0.342103             | MATCH\n",
      "\n",
      "✅ SUCCESS: The first 10 rows of the DataFrame mapped perfectly to Trial 0, Time 0-9.\n"
     ]
    }
   ],
   "source": [
    "verify_segmentation(full_yX_timeseries_df, save_path, pid='P124', gesture_num=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5672c4d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fl_torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
